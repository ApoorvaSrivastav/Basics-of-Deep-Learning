{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=[[1,2,3],[4,6,2],[5,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = torch.tensor(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [6],\n",
       "        [2],\n",
       "        [5],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.reshape(9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.reshape(3,3).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=torch.Tensor()\n",
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "# 3 attributes or Pytorrch tensor: dtype, device, layout\n",
    "print(t.dtype)\n",
    "print(t.device)\n",
    "print(t.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "t=t.cuda()\n",
    "print(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "d =torch.tensor([1,2],dtype = torch.int)\n",
    "e =torch.tensor([2,3],dtype = torch.float32)\n",
    "f = d + e\n",
    "print(f.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [0., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.1818, 0.0138],\n",
      "        [0.2945, 0.9986],\n",
      "        [0.8232, 0.3540]])\n"
     ]
    }
   ],
   "source": [
    "#creating tensors without data\n",
    "t=torch.eye(2)\n",
    "print(t)\n",
    "x=torch.zeros((3,2))\n",
    "print(x)\n",
    "x=torch.ones((3,2))\n",
    "print(x)\n",
    "x=torch.rand((3,2))\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "tensor([3., 4., 5.])\n",
      "tensor([3, 4, 5], dtype=torch.int32)\n",
      "tensor([3, 4, 5], dtype=torch.int32)\n",
      "tensor([3, 4, 5], dtype=torch.int32)\n",
      "tensor([1, 2, 3], dtype=torch.int32) tensor([1., 2., 3.], dtype=torch.float64) tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# creating tensor with data \n",
    "data = np.array([3,4,5])\n",
    "print(data.dtype)\n",
    "type(data) \n",
    "\n",
    "o1= torch.Tensor(data)\n",
    "o2= torch.tensor(data)\n",
    "o3= torch.as_tensor(data)\n",
    "o4= torch.from_numpy(data)\n",
    "\n",
    "print(o1)\n",
    "print(o2)\n",
    "print(o3)\n",
    "print(o4)\n",
    "# the first one is a constructor function while the other 3 are factory functions. Factory functions are the functions to create the \n",
    "# object of the class just like constructor but they have various other features to infer the data\n",
    "# That's why the torch.Tensor() gives the output with  default data type while all the other factory functions\n",
    "# infer the incoming data to be of int32 type and hence make the output of int32 type\n",
    "torch.get_default_dtype()   #this is the default data type of pytorch\n",
    "# factory functions also allow to set the data type explicitly\n",
    "a= torch.tensor(np.array([1,2,3]))\n",
    "b = torch.tensor(np.array([1.,2.,3.]))\n",
    "c =torch.tensor(np.array([1,2,3]),dtype= torch.float64)\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 4., 5.])\n",
      "tensor([3, 4, 5], dtype=torch.int32)\n",
      "tensor([5, 5, 5], dtype=torch.int32)\n",
      "tensor([5, 5, 5], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#Memory: Sharing vs Copying\n",
    "data[0]=5\n",
    "data[1]=5\n",
    "data[2]=5\n",
    "print(o1)\n",
    "print(o2)\n",
    "print(o3)\n",
    "print(o4)\n",
    "# changing the numpy array changed the tensor for the torch.as_tensor() and torch.from_numpy() because they share the memory while \n",
    "# there was no change in torch.tensor() and torch.Tensor() as they create a new copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 2., 4.],\n",
      "        [5., 6., 6., 7.],\n",
      "        [8., 9., 1., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Essential tensor Operations\n",
    "\n",
    "t = torch.tensor([[2,3,2,4],[5,6,6,7],[8,9,1,0]],dtype=torch.float64)\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t.shape)  #rank of the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(t.shape).prod()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numel()   #tells the number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 2., 4., 5., 6., 6., 7., 8., 9., 1., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape((1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 2.],\n",
       "        [4., 5., 6.],\n",
       "        [6., 7., 8.],\n",
       "        [9., 1., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape((4,3)) # point to notice is reshaping (3,4) to (4,3) doesn't takes the transpose rather it just re-arranges the numbers\n",
    "                 # starting from index 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 3., 2.]],\n",
       "\n",
       "        [[4., 5., 6.]],\n",
       "\n",
       "        [[6., 7., 8.]],\n",
       "\n",
       "        [[9., 1., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape((4,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 3.],\n",
       "         [2., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [6., 7.]],\n",
       "\n",
       "        [[8., 9.],\n",
       "         [1., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape((3,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape((2,3,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2., 3.],\n",
      "         [2., 4.],\n",
      "         [5., 6.]],\n",
      "\n",
      "        [[6., 7.],\n",
      "         [8., 9.],\n",
      "         [1., 0.]]], dtype=torch.float64)\n",
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "#reshape can change the rank   if there are 3 numbers mentioned in reshape, its basically 2 dimension\n",
    "#(3,4)--> (2,3,2) means 2 elements and each element is in  (3,2) shape. So the rank becomes 3,\n",
    "#but the numberof elements never change\n",
    "t=t.reshape((2,3,2))\n",
    "print(t)\n",
    "print(t.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 2., 4., 5., 6., 6., 7., 8., 9., 1., 0.], dtype=torch.float64)\n",
      "torch.Size([12])\n",
      "tensor([[2., 3., 2., 4., 5., 6., 6., 7., 8., 9., 1., 0.]], dtype=torch.float64)\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "# squeeze and unsqueeze only work if one of the dimension is 1 \n",
    "# squeeze and unsqueeze can change the rank by taking away or adding one rank if one of the dimension is 1\n",
    "q=t.reshape((12,1)).squeeze()\n",
    "print(q)\n",
    "print(q.shape)\n",
    "p=q.unsqueeze(dim=0)\n",
    "print(p)\n",
    "print(p.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2., 3., 2.],\n",
      "         [4., 5., 6.]],\n",
      "\n",
      "        [[6., 7., 8.],\n",
      "         [9., 1., 0.]]], dtype=torch.float64)\n",
      "tensor([2., 3., 2., 4., 5., 6., 6., 7., 8., 9., 1., 0.], dtype=torch.float64)\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# flatten function just creates a vector by concatinating all the existing dimension in a single row\n",
    "#flatten basically reshapes and squeeze together\n",
    "print(q.reshape((2,2,3)))\n",
    "print(q.flatten())\n",
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2., 3., 2.],\n",
      "         [4., 5., 6.]],\n",
      "\n",
      "        [[6., 7., 8.],\n",
      "         [9., 1., 0.]]], dtype=torch.float64)\n",
      "tensor([2., 3., 2., 4., 5., 6., 6., 7., 8., 9., 1., 0.], dtype=torch.float64)\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "#by using -1 we can use reshape to do what flatten does\n",
    "print(q.reshape((2,2,3)))\n",
    "print(torch.reshape(q,(-1,)))\n",
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "torch.Size([1, 12])\n",
      "tensor([2., 3., 2., 4., 5., 6., 6., 7., 8., 9., 1., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#my own flatten function \n",
    "def flat(a):\n",
    "    a=a.reshape((1,-1))\n",
    "    print(a.shape)\n",
    "    a=a.squeeze()\n",
    "    return a\n",
    "print(t.shape)\n",
    "s=flat(t)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.],\n",
      "         [3.],\n",
      "         [2.]],\n",
      "\n",
      "        [[4.],\n",
      "         [5.],\n",
      "         [6.]],\n",
      "\n",
      "        [[6.],\n",
      "         [7.],\n",
      "         [8.]],\n",
      "\n",
      "        [[9.],\n",
      "         [1.],\n",
      "         [0.]]], dtype=torch.float64)\n",
      "tensor([2., 3., 2., 4., 5., 6., 6., 7., 8., 9., 1., 0.], dtype=torch.float64) torch.Size([12])\n",
      "tensor([[2., 3., 2.],\n",
      "        [4., 5., 6.],\n",
      "        [6., 7., 8.],\n",
      "        [9., 1., 0.]], dtype=torch.float64)\n",
      "torch.Size([4, 3])\n",
      "tensor([[2.],\n",
      "        [3.],\n",
      "        [2.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.],\n",
      "        [1.],\n",
      "        [0.]], dtype=torch.float64) torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "#different axes alomg which we can flatten the tensor\n",
    "t=t.reshape((4,3,1))\n",
    "print(t)\n",
    "q=t.flatten()\n",
    "p=t.flatten(start_dim=1)\n",
    "print(q,q.shape)\n",
    "print(p)\n",
    "print(p.shape)\n",
    "s=t.flatten(end_dim=1)\n",
    "print(s,s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5]]) \n",
      " tensor([[6, 3, 4],\n",
      "        [3, 4, 8]]) \n",
      " tensor([[1, 2, 3],\n",
      "        [3, 4, 5],\n",
      "        [6, 3, 4],\n",
      "        [3, 4, 8]]) \n",
      " tensor([[1, 2, 3, 6, 3, 4],\n",
      "        [3, 4, 5, 3, 4, 8]]) \n",
      " torch.Size([4, 3]) \n",
      " torch.Size([2, 6])\n",
      "tensor([[[1, 2, 3],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[6, 3, 4],\n",
      "         [3, 4, 8]]]) n torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#concatenating is merging elements along existing axes with no change in rank \n",
    "#stacking is merging tensors as elements of a new axesy, hence stacking changes the rank\n",
    "#stacking is used to create batch\n",
    "t1=torch.tensor([[1,2,3],[3,4,5]])\n",
    "t2=torch.tensor([[6,3,4],[3,4,8]])\n",
    "t3=torch.cat((t1,t2),dim=0)\n",
    "t4=torch.cat((t1,t2),dim=1)\n",
    "print(t1,'\\n',t2,'\\n',t3,'\\n',t4,'\\n',t3.shape,'\\n',t4.shape)\n",
    "t5=torch.stack((t1,t2))\n",
    "print(t5,'n',t5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3])\n",
      "torch.Size([3, 2, 3])\n",
      "torch.Size([3, 1, 2, 3])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([1, 2, 3])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "#Element wise access operation \n",
    "a= torch.tensor([[1,2,3],[4,5,6]])\n",
    "b= torch.tensor([[0,5,4],[4,8,3]])\n",
    "c= torch.tensor([[5,2,6],[6,3,9]])\n",
    "print(a.shape,b.shape,c.shape)\n",
    "tens= torch.stack((a,b,c))\n",
    "print(tens.shape)\n",
    "tens= tens.reshape([3,1,2,3])\n",
    "print(tens.shape)\n",
    "# this is like concatenating 3: 2x3 images with one color channel \n",
    "print(tens[0])   #first image of the batch\n",
    "print(tens[0][0]) #first channel of first image of the batch\n",
    "print(tens[0][0][0]) #first row of the first channel of first image of the batch\n",
    "print(tens[0][0][0][0]) #first pixel value of the first row of the first channel of first image of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 0, 5, 4, 4, 8, 3, 5, 2, 6, 6, 3, 9])\n",
      "tensor([1, 2, 3, 4, 5, 6, 0, 5, 4, 4, 8, 3, 5, 2, 6, 6, 3, 9])\n",
      "tensor([1, 2, 3, 4, 5, 6, 0, 5, 4, 4, 8, 3, 5, 2, 6, 6, 3, 9])\n",
      "tensor([1, 2, 3, 4, 5, 6, 0, 5, 4, 4, 8, 3, 5, 2, 6, 6, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "#ways to flatten tensor\n",
    "print(tens.flatten())\n",
    "print(tens.reshape(1,-1)[0])\n",
    "print(tens.reshape(-1))\n",
    "print(tens.view(tens.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5, 6],\n",
      "        [0, 5, 4, 4, 8, 3],\n",
      "        [5, 2, 6, 6, 3, 9]])\n",
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "print(tens.flatten(start_dim=1))\n",
    "print(tens.flatten(start_dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5, 6],\n",
      "        [0, 5, 4, 4, 8, 3],\n",
      "        [5, 2, 6, 6, 3, 9]])\n",
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# another way to flatten only desired dimension using reshape instead of flatten\n",
    "print(tens.reshape(tens.shape[0],-1))\n",
    "print(tens.reshape(tens.shape[0],-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELEMENT WISE OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([[1,2],[3,4]],dtype = torch.float32)\n",
    "t2 = torch.tensor([[5,0],[6,8]],dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  2.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "#for any kind of elemnt wise operation we need the 2 tensors to be of the same size\n",
    "t1 = t1 +t2\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Tensor Broadcasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.,  4.],\n",
      "        [11., 14.]])\n",
      "tensor([[ 8.,  4.],\n",
      "        [11., 14.]])\n",
      "tensor([[12.,  4.],\n",
      "        [18., 24.]])\n",
      "tensor([[12.,  4.],\n",
      "        [18., 24.]])\n",
      "tensor([[3.0000, 1.0000],\n",
      "        [4.5000, 6.0000]])\n",
      "tensor([[3.0000, 1.0000],\n",
      "        [4.5000, 6.0000]])\n",
      "tensor([[ 4.,  0.],\n",
      "        [ 7., 10.]])\n",
      "tensor([[ 4.,  0.],\n",
      "        [ 7., 10.]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting in case of scalar even if scalar's shape doesn't match with the tensor\n",
    "print(t1 + 2)\n",
    "print(t1.add(2))\n",
    "print(t1 * 2)\n",
    "print(t1.mul(2))\n",
    "print(t1/2)\n",
    "print(t1.div(2))\n",
    "print(t1 - 2)\n",
    "print(t1.sub(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "t2 = np.broadcast_to(2,t1.shape)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14., 10.],\n",
      "        [17., 20.]])\n"
     ]
    }
   ],
   "source": [
    "k =t1+2\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14., 10.],\n",
      "        [17., 20.]]) \n",
      " tensor([[12.,  8.],\n",
      "        [15., 18.]])\n"
     ]
    }
   ],
   "source": [
    "k2 = t1 + torch.tensor(np.broadcast_to(2,t1.shape),dtype=torch.float32)\n",
    "print(k2,'\\n',t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [4., 6.]])\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor([[1,2],[3,4]],dtype=torch.float32)\n",
    "a2 = torch.tensor([1,2],dtype=torch.float32)\n",
    "\n",
    "a3 = a1+a2\n",
    "print(a3)\n",
    "print(np.broadcast_to(a2.numpy(),a1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting has multiple other applications but the basic requirement arise for the element-wise \n",
    "# operation which requires the two tensors to be of same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False],\n",
      "        [False,  True, False]])\n",
      "tensor([[False, False,  True],\n",
      "        [ True,  True,  True]])\n",
      "tensor([[False, False,  True],\n",
      "        [ True,  True,  True]])\n",
      "tensor([[ True,  True,  True],\n",
      "        [ True,  True, False]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "#element-wise Comparision Operation\n",
    "t1 = torch.tensor([[1,2,4],[4,5,6]],dtype= torch.float32)\n",
    "print(t1.eq(5))\n",
    "print(t1.gt(2))\n",
    "print(t1.ge(3))\n",
    "print(t1.lt(6))\n",
    "print(t1.le(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4142, 1.7321, 2.0000],\n",
      "        [1.7321,    nan, 1.0000]])\n",
      "tensor([[2., 3., 4.],\n",
      "        [3., 4., 1.]])\n",
      "tensor([[-2., -3., -4.],\n",
      "        [-3.,  4., -1.]])\n",
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "# Element wise function application\n",
    "t1 =torch.tensor([[2,3,4],[3,-4,1]], dtype = torch.float32)\n",
    "print(t1.sqrt())\n",
    "print(t1.abs())\n",
    "print(t1.neg())\n",
    "print(t1.mean()) # not an element wise operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(31.)\n",
      "9\n",
      "1\n",
      "True\n",
      "tensor(22680.)\n",
      "tensor(1.7401)\n",
      "tensor(3.4444)\n"
     ]
    }
   ],
   "source": [
    "# Arg Max and Reduction Tensor Operation\n",
    "# Reduction Operation is an operation which when performed on a tensor reduces the number of \n",
    "# elements contained in the tensor. Or its a way to perform the operation among the elements \n",
    "# of the tensor\n",
    "t = torch.tensor([[1,3,4],[3,5,2],[3,7,3]],dtype = torch.float32)\n",
    "print(t.sum())\n",
    "print(t.numel())\n",
    "print(t.sum().numel())\n",
    "print(t.sum().numel()<t.numel())\n",
    "print(t.prod())\n",
    "print(t.std())\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 6., 6., 6.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([ 4.,  8., 12.])\n",
      "tensor(4.) tensor(8.) tensor(12.)\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1,1,1,1],[2,2,2,2],[3,3,3,3]],dtype = torch.float32)\n",
    "print(t.sum(dim=0))\n",
    "print(t[0] + t[1] +t[2])\n",
    "print(t.sum(dim=1))\n",
    "print(t[0].sum() , t[1].sum() , t[2].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(46.)\n",
      "tensor(5)\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[3,5,0,2],[23,46,35,4],[2,8,2,6]],dtype=torch.float32)\n",
    "print(t.max())\n",
    "print(t.argmax())\n",
    "print(t.flatten().argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([23., 46., 35.,  6.]),\n",
      "indices=tensor([1, 1, 1, 2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([ 5., 46.,  8.]),\n",
      "indices=tensor([1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "#watch it carefully to understand; for a 3x4 vector \n",
    "#dim0 will have 4 elements, dim1 will have 3 elements after the reduction operation \n",
    "print(t.max(dim=0))\n",
    "print(t.max(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.,  5.,  0.,  2.],\n",
      "         [23., 46., 35.,  4.],\n",
      "         [29.,  8., 23.,  6.]],\n",
      "\n",
      "        [[31.,  5., 70.,  2.],\n",
      "         [20.,  6., 32., 40.],\n",
      "         [25., 18., 12., 65.]]])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.return_types.max(\n",
      "values=tensor([[31.,  5., 70.,  2.],\n",
      "        [23., 46., 35., 40.],\n",
      "        [29., 18., 23., 65.]]),\n",
      "indices=tensor([[1, 1, 1, 1],\n",
      "        [0, 0, 0, 1],\n",
      "        [0, 1, 0, 1]]))\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [0, 0, 0, 1],\n",
      "        [0, 1, 0, 1]])\n",
      "torch.return_types.max(\n",
      "values=tensor([[29., 46., 35.,  6.],\n",
      "        [31., 18., 70., 65.]]),\n",
      "indices=tensor([[2, 1, 1, 2],\n",
      "        [0, 2, 0, 2]]))\n",
      "tensor([[2, 1, 1, 2],\n",
      "        [0, 2, 0, 2]])\n",
      "torch.return_types.max(\n",
      "values=tensor([[ 5., 46., 29.],\n",
      "        [70., 40., 65.]]),\n",
      "indices=tensor([[1, 1, 0],\n",
      "        [2, 3, 3]]))\n",
      "tensor([[1, 1, 0],\n",
      "        [2, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "#dim0 will have 2-3x4 elements,after the reduction operation \n",
    "#dim1 will have 3-2x4 elements,after the reduction operation \n",
    "#dim0 will have 4-2x3 elements,after the reduction operation \n",
    "t = torch.tensor([[[3,5,0,2],[23,46,35,4],[29,8,23,6]],[[31,5,70,2],[20,6,32,40],[25,18,12,65]]],dtype=torch.float32)\n",
    "print(t)\n",
    "print(t.shape)\n",
    "print(t.max(dim=0))\n",
    "print(t.argmax(dim=0))\n",
    "print(t.max(dim=1))\n",
    "print(t.argmax(dim=1))\n",
    "print(t.max(dim=2))\n",
    "print(t.argmax(dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "tensor(21.2500)\n",
      "21.25\n",
      "[[17.0, 5.0, 35.0, 2.0], [21.5, 26.0, 33.5, 22.0], [27.0, 13.0, 17.5, 35.5]]\n",
      "[[18.333334 19.666666 19.333334  4.      ]\n",
      " [25.333334  9.666667 38.       35.666668]]\n"
     ]
    }
   ],
   "source": [
    "#accessing elements of tensor\n",
    "print(t.shape)\n",
    "print(t.mean())\n",
    "print(t.mean().item())\n",
    "print(t.mean(dim=0).tolist())\n",
    "print(t.mean(dim=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
