{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MNIST datasets are hosted on yann.lecun.com that has moved under CloudFlare protection\n",
    "# Run this script to enable the datasets download\n",
    "# Reference: https://github.com/pytorch/vision/issues/1938\n",
    "\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms   #torchvision has datasets related to CV\n",
    "# define a transform to normalize/pre-process the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,)),])\n",
    "\n",
    "# Download and divide data into batches\n",
    "train_data = datasets.MNIST('~/.pytorch/MNIST_data/',download=True,train=True,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(train_data,batch_size=64,shuffle=True) #converts data into batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3057, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Losses are provided using criterion varible as a convention. For Classification problem we use \n",
    "# Cross Entropy loss which in pytorch takes care of Softmax itself so we need to provide the raw values\n",
    "# Cross entropy is a combination of Softmax loss and negative log likelihood loss\n",
    "input_size = 784\n",
    "hidden_layer_sizes = [128,64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size,hidden_layer_sizes[0]),nn.ReLU(),\n",
    "                     nn.Linear(hidden_layer_sizes[0],hidden_layer_sizes[1]), nn.ReLU(),\n",
    "                     nn.Linear(hidden_layer_sizes[1],output_size))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# forward pass \n",
    "train_data_iter = iter(trainloader)\n",
    "images, labels = train_data_iter.next()\n",
    "images.resize_(images.shape[0],784)\n",
    "probabs = model.forward(images)\n",
    "\n",
    "Loss= criterion(probabs,labels)\n",
    "print(Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss. Note that for nn.LogSoftmax and F.log_softmax you'll need to set the dim keyword argument appropriately. dim=0 calculates softmax across the rows, so each column sums to 1, while dim=1 calculates across the columns so each row sums to 1. Think about what you want the output to be and choose dim appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3021, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_layer_sizes = [128,64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size,hidden_layer_sizes[0]),nn.ReLU(),\n",
    "                     nn.Linear(hidden_layer_sizes[0],hidden_layer_sizes[1]), nn.ReLU(),\n",
    "                     nn.Linear(hidden_layer_sizes[1],output_size),nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "# forward pass \n",
    "train_data_iter = iter(trainloader)\n",
    "images, labels = train_data_iter.next()\n",
    "images.resize_(images.shape[0],784)\n",
    "probabs = model.forward(images)\n",
    "\n",
    "Loss= criterion(probabs,labels)\n",
    "print(Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd and Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x000002074910CDC8>\n",
      "tensor([[0.5531, 0.3799],\n",
      "        [0.5773, 1.3026]])\n",
      "tensor([[0.5531, 0.3799],\n",
      "        [0.5773, 1.3026]], grad_fn=<MulBackward0>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Here backward() can be applied only to the scalar outputs\n",
    "# for a scalar output gradient can be calculated with those variables which had requires_grad= True while their creation \n",
    "x = torch.randn(2,2,requires_grad= True)\n",
    "y = x**3\n",
    "z = torch.mean(y)\n",
    "\n",
    "print(y.grad_fn)\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(.75* x**2)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3037, grad_fn=<NllLossBackward>)\n",
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-9.2854e-04, -9.2854e-04, -9.2854e-04,  ..., -9.2854e-04,\n",
      "         -9.2854e-04, -9.2854e-04],\n",
      "        [ 4.6685e-03,  4.6685e-03,  4.6685e-03,  ...,  4.6685e-03,\n",
      "          4.6685e-03,  4.6685e-03],\n",
      "        [-6.4598e-05, -6.4598e-05, -6.4598e-05,  ..., -6.4598e-05,\n",
      "         -6.4598e-05, -6.4598e-05],\n",
      "        ...,\n",
      "        [ 1.9165e-03,  1.9165e-03,  1.9165e-03,  ...,  1.9165e-03,\n",
      "          1.9165e-03,  1.9165e-03],\n",
      "        [ 3.4352e-04,  3.4352e-04,  3.4352e-04,  ...,  3.4352e-04,\n",
      "          3.4352e-04,  3.4352e-04],\n",
      "        [-3.8625e-04, -3.8625e-04, -3.8625e-04,  ..., -3.8625e-04,\n",
      "         -3.8625e-04, -3.8625e-04]])\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_layer_sizes = [128,64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size,hidden_layer_sizes[0]),nn.ReLU(),\n",
    "                     nn.Linear(hidden_layer_sizes[0],hidden_layer_sizes[1]), nn.ReLU(),\n",
    "                     nn.Linear(hidden_layer_sizes[1],output_size),nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "# forward pass \n",
    "train_data_iter = iter(trainloader)\n",
    "images, labels = train_data_iter.next()\n",
    "images.resize_(images.shape[0],784)\n",
    "probabs = model.forward(images)\n",
    "\n",
    "Loss= criterion(probabs,labels)\n",
    "print(Loss)\n",
    "\n",
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "Loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Package Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01)  #Defining SGD optimizer object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "\n",
    "The steps for training/learning from a batch of data are described in the comments below:\n",
    "1. Clear the gradients of all optimized variables\n",
    "2. Forward pass: compute predicted outputs by passing inputs to the model\n",
    "3. Calculate the loss\n",
    "4. Backward pass: compute gradient of the loss with respect to model parameters\n",
    "5. Perform a single optimization step (parameter update)\n",
    "6. Update average training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights Parameter containing:\n",
      "tensor([[-0.0235,  0.0190, -0.0145,  ...,  0.0086, -0.0213, -0.0144],\n",
      "        [-0.0163,  0.0047,  0.0180,  ...,  0.0116,  0.0338,  0.0325],\n",
      "        [ 0.0241, -0.0041, -0.0321,  ...,  0.0346,  0.0124,  0.0264],\n",
      "        ...,\n",
      "        [-0.0154, -0.0104,  0.0238,  ..., -0.0261,  0.0238,  0.0152],\n",
      "        [-0.0106,  0.0081, -0.0044,  ..., -0.0165,  0.0086, -0.0099],\n",
      "        [ 0.0156,  0.0314, -0.0050,  ..., -0.0012, -0.0312,  0.0052]],\n",
      "       requires_grad=True)\n",
      "Weights before update Parameter containing:\n",
      "tensor([[-0.0235,  0.0190, -0.0145,  ...,  0.0086, -0.0213, -0.0144],\n",
      "        [-0.0163,  0.0047,  0.0180,  ...,  0.0116,  0.0338,  0.0325],\n",
      "        [ 0.0241, -0.0041, -0.0321,  ...,  0.0346,  0.0124,  0.0264],\n",
      "        ...,\n",
      "        [-0.0154, -0.0104,  0.0238,  ..., -0.0261,  0.0238,  0.0152],\n",
      "        [-0.0106,  0.0081, -0.0044,  ..., -0.0165,  0.0086, -0.0099],\n",
      "        [ 0.0156,  0.0314, -0.0050,  ..., -0.0012, -0.0312,  0.0052]],\n",
      "       requires_grad=True)\n",
      "Gradients tensor([[-0.0045, -0.0045, -0.0045,  ..., -0.0045, -0.0045, -0.0045],\n",
      "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        [ 0.0031,  0.0031,  0.0031,  ...,  0.0031,  0.0031,  0.0031],\n",
      "        ...,\n",
      "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
      "        [-0.0013, -0.0013, -0.0013,  ..., -0.0013, -0.0013, -0.0013]])\n",
      "Weights after update Parameter containing:\n",
      "tensor([[-0.0235,  0.0190, -0.0145,  ...,  0.0086, -0.0213, -0.0144],\n",
      "        [-0.0163,  0.0047,  0.0180,  ...,  0.0116,  0.0338,  0.0325],\n",
      "        [ 0.0241, -0.0041, -0.0321,  ...,  0.0346,  0.0124,  0.0264],\n",
      "        ...,\n",
      "        [-0.0154, -0.0104,  0.0238,  ..., -0.0261,  0.0238,  0.0152],\n",
      "        [-0.0106,  0.0081, -0.0044,  ..., -0.0165,  0.0086, -0.0099],\n",
      "        [ 0.0156,  0.0314, -0.0050,  ..., -0.0012, -0.0312,  0.0052]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Step 0: Define the model \n",
    "input_size = 784\n",
    "hidden_layer_sizes = [128,64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size,hidden_layer_sizes[0]),nn.ReLU(),\n",
    "                     nn.Linear(hidden_layer_sizes[0],hidden_layer_sizes[1]), nn.ReLU(),\n",
    "                     nn.Linear(hidden_layer_sizes[1],output_size),nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01)  #Defining SGD optimizer object\n",
    "print('Initial Weights',model[0].weight)\n",
    "\n",
    "#Step 1: Make a forward pass\n",
    "data_iter = iter(trainloader)\n",
    "images, labels = data_iter.next()\n",
    "images.resize_(images.shape[0],784)\n",
    "\n",
    "optimizer.zero_grad()  # very important to make the gradients zero before every new batch is processed\n",
    "logits = model.forward(images)\n",
    "\n",
    "# Step2: Calculate Loss\n",
    "Loss = criterion(logits, labels)\n",
    "\n",
    "print('Weights before update',model[0].weight)\n",
    "# Step3: Calculate Gradients\n",
    "Loss.backward()\n",
    "\n",
    "print('Gradients',model[0].weight.grad)\n",
    "# Step4: Update Gradients \n",
    "optimizer.step()\n",
    "\n",
    "print('Weights after update',model[0].weight)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss for epoch 0 1.9049318448058579\n",
      "Avg Training Loss for epoch 1 0.8234159511162528\n",
      "Avg Training Loss for epoch 2 0.5218419579745356\n",
      "Avg Training Loss for epoch 3 0.4321939013342359\n",
      "Avg Training Loss for epoch 4 0.3870903822595377\n",
      "Avg Training Loss for epoch 5 0.358802064490725\n",
      "Avg Training Loss for epoch 6 0.33895225480580127\n",
      "Avg Training Loss for epoch 7 0.32355648320493924\n",
      "Avg Training Loss for epoch 8 0.3110601923851443\n",
      "Avg Training Loss for epoch 9 0.3000637845062752\n",
      "Avg Training Loss for epoch 10 0.2904131143951594\n",
      "Avg Training Loss for epoch 11 0.2816364640858509\n",
      "Avg Training Loss for epoch 12 0.27332965364413603\n",
      "Avg Training Loss for epoch 13 0.2657540693982387\n",
      "Avg Training Loss for epoch 14 0.2586448735464166\n"
     ]
    }
   ],
   "source": [
    "# Defining the model \n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "# Loops for epochs\n",
    "Epoch=15\n",
    "for i in range(Epoch):\n",
    "    running_loss=0\n",
    "    for images,labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        scores = model.forward(images)\n",
    "        \n",
    "        Loss = criterion(scores,labels)\n",
    "        \n",
    "        Loss.backward()\n",
    "        running_loss += Loss.item()\n",
    "        optimizer.step()\n",
    "    print(\"Avg Training Loss for epoch\",i,running_loss/len(trainloader))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHwCAYAAAC7cCafAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAABYlAAAWJQFJUiTwAAAeYElEQVR4nO3dedRkdXkn8O8DrSAtixCXIUbZRDKoKJggkkHAZcRMFBUMcybKGMmoMRKMZvQkanDL6EnigkbNRCNRToIecBkTXKKAoCA5aRRigqJCS1wRkEVWm/7NH1VtOu379lK3uut9f/X5nFPnvnXvfer3vLfv6e97q27dW621AAD92G7WDQAA0yXcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzK2bdwNZQVVcn2SXJ6hm3AgCT2ivJza21vbe0sMtwT7LLdtl+95XZefdZNwIAk7g1t2Rt7p6ottdwX70yO+9+aD1h1n0AwEQuaZ/JLblx9SS1M/3MvaoeWFV/VVXfrao7q2p1Vb21qu4zy74AYDmb2ZF7Ve2b5KIk90vysSRfTfLLSX43yZOr6vDW2vWz6g8AlqtZHrm/M6NgP7m1dmxr7RWttaOTvCXJQ5O8YYa9AcCyNZNwr6p9kjwpo7PZ/3yDxX+U5NYkz66qldu4NQBY9mb1tvzR4+mnW2tr11/QWrulqr6QUfg/JslnF3uRqlq1yKIDptIlACxDs3pb/qHj6ZWLLP/6eLr/NugFALoyqyP3XcfTmxZZvm7+bht7kdbaIQvNHx/RHzxRZwCwzC3Vy8/WeNpm2gUALEOzCvd1R+a7LrJ8lw3WAwA206zC/Wvj6WKfqT9kPF3sM3kAYBGzCvfzxtMnVdV/6KGqdk5yeJLbk3xxWzcGAMvdTMK9tfbNJJ/O6I43L9pg8WuSrEzy/tbardu4NQBY9mZ545jfzujys6dV1eOTXJHk0CRHZfR2/B/OsDcAWLZmdrb8+Oj90UlOzyjUX5pk3ySnJTnMdeUBYDIzveVra+3fkjx3lj0AQG+W6vfcAYAJCXcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOrJh1A7AUbL/H7hPXrr35x4PG3m6fB01c+83n3HfQ2Hfdb83EtUc+/KuDxj7/nw8YVD/EbpfdY1D9f/rk9yauvfsbVw8aGzbHzI7cq2p1VbVFHt+fVV8AsNzN+sj9piRvXWD+sEMhAJhjsw73G1trp864BwDoihPqAKAzsz5y36GqfiPJg5LcmuTyJBe01u6ebVsAsHzNOtwfkOQDG8y7uqqe21r73KaKq2rVIotmdxouAMzYLN+Wf1+Sx2cU8CuTPDzJXyTZK8knquqg2bUGAMvXzI7cW2uv2WDWV5K8oKp+nOSlSU5N8vRNvMYhC80fH9EfPIU2AWDZWYon1L17PD1ipl0AwDK1FMP92vF05Uy7AIBlaimG+2Hj6VUz7QIAlqmZhHtVHVhVP3Mx76p6cJJ3jJ+esW27AoA+zOqEuuOTvKKqzktydZJbkuyb5FeT7JjknCR/OqPeAGBZm1W4n5fkoUkeldHb8CuT3Jjk8xl97/0DrbU2o94AYFmbSbiPL1CzyYvUwOZa8fN7Dqrf88M3TVx7zY/vN2jsjxzwt4PqZ2W7gZ/qrf2Fc6fUyQSeMqz8h//7zolrj33N7w8ae4/3XjyonvmwFE+oAwAGEO4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdmcn93GHabnzvjoPqP/zAj01cO/i+5gNq/8dVxwwa+1s37T6ofl791r6fn7j2b179p4PG/p0rfnvi2rroskFjs3w4cgeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMW77ShUft8Z2ZjX3NmtsH1f/Pl7x04tp7nzPsFp6733HdoPp59Wevf9rEtR99/7WDxt7+mq9NXDvk9sIsL47cAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAz7udOF7arYXeq3m7A37lf/cnPDRp7pw9fMnGt+3PPxl6vvHji2rbTToPGvupVj5q49tCj/2XQ2A+6148mrv3KTXsOGvv2x/1gUP28ceQOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGbd8pQuf+OyjB9X/yW9cNHHtQfe8btDY1z/vsIlr93jv5LceZXLt8EdOXLvzm/5t0NiX733aoPohLrtr8tpLn7X/wNHd8nVLOHIHgM5MJdyr6riqentVXVhVN1dVq6ozNlHz2Ko6p6puqKrbquryqjqlqrafRk8AMK+m9bb8K5MclOTHSb6d5ICNrVxVT0tydpI7knwwyQ1Jfi3JW5IcnuT4KfUFAHNnWm/LvyTJ/kl2SfLCja1YVbsk+cskdyc5srX2vNba7yd5ZJKLkxxXVSdMqS8AmDtTCffW2nmtta+31tpmrH5ckvsmObO19k/rvcYdGb0DkGziDwQAYHGzOKHu6PH0kwssuyDJbUkeW1U7bLuWAKAfs/gq3EPH0ys3XNBaW1NVVyc5MMk+Sa7Y2AtV1apFFm30M38A6Nksjtx3HU9vWmT5uvm7bf1WAKA/S/EiNjWebvLz+9baIQu+wOiI/uBpNgUAy8UsjtzXHZnvusjyXTZYDwDYArMI96+Npz9zLcKqWpFk7yRrkly1LZsCgF7MItzPHU+fvMCyI5LslOSi1tqd264lAOjHLML9rCTXJTmhqn56t4+q2jHJ68dP3zWDvgCgC1M5oa6qjk1y7PjpA8bTw6rq9PHP17XWXpYkrbWbq+q3Mgr586vqzIwuP/vUjL4md1ZGl6QFACYwrbPlH5nkxA3m7TN+JMm3krxs3YLW2ker6nFJ/jDJM5PsmOQbSX4vyWmbeaU7AGABUwn31tqpSU7dwpovJHnKNMaH/U/71qD6S46/x8S1h+0w7NOtk176/yau/fgnDxo09prvfHdQ/XJ147MPG1T/x6f+34lrf2XHOwaNPcR7btpn0yttxJsvfcLEtftd+aVBY7Nl3M8dADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM9O6nzvM1NBbl/7mh18wce0V//3PB4393F1XT1z79hOfNmjsB/7x7G75uv1+ew+q/8UPTn6b31ff/82Dxt6p7jlx7dpBIw+7betfv+m/DRp7v7++eFA9244jdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDoTLXWZt3D1FXVqp2z28GH1hNm3Qrz4LMPHFT+dwd8bEqNbLlHvf3FE9feddCtg8b+lyP+alD9LP2k3T1x7cPPf/6gsQ949Y8mrl1z1epBY7NtXdI+k1ty46WttUO2tNaROwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGdWzLoBWO5W/GYNqv/S+Wsnrj3onoOGzqoXv23i2u0GHhuszeS/91AHnv+/BtX/3Cd2mLh2vzO+OGjsNYOqmReO3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM+7nDgO1H900qP6Ez71g4tornvjuQWPP0pfuHHZs8eLX/c7EtQ/52y8NGnvtHXcMqoetzZE7AHRmKuFeVcdV1dur6sKqurmqWlWdsci6e42XL/Y4cxo9AcC8mtbb8q9MclCSHyf5dpIDNqPmsiQfXWD+V6bUEwDMpWmF+0syCvVvJHlckvM2o+bLrbVTpzQ+ADA2lXBvrf00zKtqGi8JAExolmfL71lVz0+yR5Lrk1zcWrt8S16gqlYtsmhzPhYAgC7NMtyfOH78VFWdn+TE1to1M+kIADowi3C/LcnrMjqZ7qrxvEckOTXJUUk+W1WPbK3duqkXaq0dstD88RH9wdNoFgCWm23+PffW2rWttVe31i5trd04flyQ5ElJLkmyX5KTtnVfANCLJXMRm9bamiTvGT89Ypa9AMBytmTCfeyH4+nKmXYBAMvYUgv3x4ynV210LQBgUds83Kvq0Kq65wLzj87oYjhJsuClawGATZvK2fJVdWySY8dPHzCeHlZVp49/vq619rLxz29KcuD4a2/fHs97RJKjxz+/qrV20TT6AoB5NK2vwj0yyYkbzNtn/EiSbyVZF+4fSPL0JL+U5Jgk90jygyQfSvKO1tqFU+oJAObStC4/e2pG31PfnHXfm+S90xgXloLrnnHgoPornnjalDpZXt5//eGD6nd/38UT164dNDIsfUvthDoAYCDhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdmdb93GFZu+sfHjxx7T8e+K5BY/+kTf439v6ffP6gsX/h45OP/ddve/Ogsd+25xcG1R/5rBdNXHvvD31x0Niw1DlyB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOuJ87Xbj+eYcNqv/wQ/9k4tqftHsNGvvE1U+YuPY/v/q7g8Ze853J64/+1ZcMGvurT3nnoPrff8MZE9e+89vPHDR2XXTZoHrY2hy5A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdMYtX+nCY15w6aD6+2+/w8S1D/v8cweNvd/vXTdx7ZBbtg71kPfdNaj+E0feZ1D9MTv9aOLat7928tokucfLD5y4tq36l0Fjw+Zw5A4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnXE/dxhor1+/fFD9min1sa3VRZcNqn/nic8cVL/T+/9m4tpzfvHsQWMf9NTfnbj2wasGDQ2bZfCRe1XtUVUnVdVHquobVXV7Vd1UVZ+vqudV1YJjVNVjq+qcqrqhqm6rqsur6pSq2n5oTwAwz6Zx5H58kncl+V6S85Jck+T+SZ6R5D1Jjqmq41trbV1BVT0tydlJ7kjywSQ3JPm1JG9Jcvj4NQGACUwj3K9M8tQkf99aW7tuZlX9QZJ/TPLMjIL+7PH8XZL8ZZK7kxzZWvun8fxXJTk3yXFVdUJr7cwp9AYAc2fw2/KttXNbax9fP9jH87+f5N3jp0eut+i4JPdNcua6YB+vf0eSV46fvnBoXwAwr7b22fI/GU/XP2fo6PH0kwusf0GS25I8tqp22JqNAUCvttrZ8lW1Islzxk/XD/KHjqdXbljTWltTVVcnOTDJPkmu2MQYi513esCWdQsA/diaR+5vTPKwJOe01j613vxdx9ObFqlbN3+3rdQXAHRtqxy5V9XJSV6a5KtJnr2l5eNp2+haSVprhywy/qokB2/huADQhakfuVfVi5K8Lcm/JjmqtXbDBqusOzLfNQvbZYP1AIAtMNVwr6pTkrwjyVcyCvbvL7Da18bT/ReoX5Fk74xOwLtqmr0BwLyYWrhX1cszugjNlzMK9msXWfXc8fTJCyw7IslOSS5qrd05rd4AYJ5MJdzHF6B5Y5JVSR7fWrtuI6ufleS6JCdU1aPXe40dk7x+/PRd0+gLAObR4BPqqurEJK/N6IpzFyY5uao2XG11a+30JGmt3VxVv5VRyJ9fVWdmdPnZp2b0NbmzMrokLQAwgWmcLb/3eLp9klMWWedzSU5f96S19tGqelySP8zo8rQ7JvlGkt9Lctr616EHALZM9ZijVbVq5+x28KH1hFm3wjay8oL7Dqr/4L4LXTBx8/zKK35n0Ni7feDiQfXzasi/+ZB/7yT59O0rJ649bT/X2GLzXNI+k1ty46WLfe17Y7b25WcBgG1MuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRmxawbgGm446RdBtUf/5dPmbj27Df8yaCxn3HCcyeuXfvhnxs09r2/u2bi2u3vXDto7BXnrhpU/7137ztx7dX/545BY++83fYT1674+T0Hjb3mO98dVM98cOQOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGbd8pQt3X/nNQfW3P27y2l9/1ssGjb3XyV+fuPYDr/2bQWMPccvauwbVn/r9owfVn3y/P5u49sEr7jlo7L1X3D1x7Q3vudegsXc5ZlA5c8KROwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0xv3cYaB7f+iLg+pv+budJq59+gNPGDT2115434lr166c/J7mSfLyXzlnUP3Qe7IPcc2a2yeu3eEduw8c/ZsD65kHjtwBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6U621WfcwdVW1aufsdvCh9YRZtwIAE7mkfSa35MZLW2uHbGmtI3cA6MzgcK+qParqpKr6SFV9o6pur6qbqurzVfW8qtpug/X3qqq2kceZQ3sCgHm2YgqvcXySdyX5XpLzklyT5P5JnpHkPUmOqarj28++/39Zko8u8HpfmUJPADC3phHuVyZ5apK/b62tXTezqv4gyT8meWZGQX/2BnVfbq2dOoXxAYD1DH5bvrV2bmvt4+sH+3j+95O8e/z0yKHjAACbZxpH7hvzk/F0zQLL9qyq5yfZI8n1SS5urV2+lfsBgO5ttXCvqhVJnjN++skFVnni+LF+zflJTmytXbOZY6xaZNEBm9kmAHRna34V7o1JHpbknNbap9abf1uS1yU5JMl9xo/HZXQy3pFJPltVK7diXwDQta1y5F5VJyd5aZKvJnn2+staa9cmefUGJRdU1ZOSfD7JoUlOSvK2TY2z2Bf7x0f0B2955wCw/E39yL2qXpRRMP9rkqNaazdsTl1rbU1GX51LkiOm3RcAzIuphntVnZLkHRl9V/2o8RnzW+KH46m35QFgQlML96p6eZK3JPlyRsF+7QQv85jx9Kpp9QUA82Yq4V5Vr8roBLpVSR7fWrtuI+seWlX3XGD+0UleMn56xjT6AoB5NPiEuqo6Mclrk9yd5MIkJ1fVhqutbq2dPv75TUkOHH/t7dvjeY9IcvT451e11i4a2hcAzKtpnC2/93i6fZJTFlnnc0lOH//8gSRPT/JLSY5Jco8kP0jyoSTvaK1dOIWeAGBuDQ738fXhT92C9d+b5L1DxwUAFuZ+7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQmWqtzbqHqauq67fL9ruvzM6zbgUAJnJrbsna3H1Da22PLa1dsTUaWgJuXpu7c0tuXL3I8gPG069uo356YJtNxnabjO225WyzySzl7bZXkpsnKezyyH1TqmpVkrTWDpl1L8uFbTYZ220yttuWs80m0+t285k7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRmLs+WB4CeOXIHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM7MVbhX1QOr6q+q6rtVdWdVra6qt1bVfWbd21I03j5tkcf3Z93fLFXVcVX19qq6sKpuHm+TMzZR89iqOqeqbqiq26rq8qo6paq231Z9z9qWbLeq2msj+1+rqjO3df+zUFV7VNVJVfWRqvpGVd1eVTdV1eer6nlVteD/4/O+v23pduttf+v1fu4/o6r2TXJRkvsl+VhG9+795SS/m+TJVXV4a+36Gba4VN2U5K0LzP/xNu5jqXllkoMy2g7fzr/fE3pBVfW0JGcnuSPJB5PckOTXkrwlyeFJjt+azS4hW7Tdxi5L8tEF5n9lem0taccneVeS7yU5L8k1Se6f5BlJ3pPkmKo6vq13RTL7W5IJtttYH/tba20uHkk+laQlefEG8988nv/uWfe41B5JVidZPes+luIjyVFJHpKkkhw53ofOWGTdXZJcm+TOJI9eb/6OGf3B2ZKcMOvfaQlut73Gy0+fdd8z3mZHZxTM220w/wEZBVZL8sz15tvfJttuXe1vc/G2fFXtk+RJGYXVn2+w+I+S3Jrk2VW1chu3xjLVWjuvtfb1Nv5fYROOS3LfJGe21v5pvde4I6Mj2SR54VZoc8nZwu1Gktbaua21j7fW1m4w//tJ3j1+euR6i+xvmWi7dWVe3pY/ejz99AL/0LdU1RcyCv/HJPnstm5uiduhqn4jyYMy+iPo8iQXtNbunm1by8q6/e+TCyy7IMltSR5bVTu01u7cdm0tG3tW1fOT7JHk+iQXt9Yun3FPS8VPxtM1682zv23aQtttnS72t3kJ94eOp1cusvzrGYX7/hHuG3pAkg9sMO/qqnpua+1zs2hoGVp0/2utramqq5McmGSfJFdsy8aWiSeOHz9VVecnObG1ds1MOloCqmpFkueMn64f5Pa3jdjIdluni/1tLt6WT7LreHrTIsvXzd9t67eyrLwvyeMzCviVSR6e5C8y+mzqE1V10OxaW1bsf5O5LcnrkhyS5D7jx+MyOjnqyCSfnfOP0t6Y5GFJzmmtfWq9+fa3jVtsu3W1v81LuG9Kjac+B1xPa+0148+tftBau6219pXW2gsyOgnxXklOnW2H3bD/LaC1dm1r7dWttUtbazeOHxdk9C7bJUn2S3LSbLucjao6OclLM/rWz7O3tHw8nbv9bWPbrbf9bV7Cfd1fqrsusnyXDdZj49adjHLETLtYPux/U9RaW5PRV5mSOdwHq+pFSd6W5F+THNVau2GDVexvC9iM7bag5bq/zUu4f2083X+R5Q8ZTxf7TJ7/6NrxdNm8RTVji+5/48//9s7oxJ6rtmVTy9wPx9O52ger6pQk78joO9dHjc/83pD9bQObud02Ztntb/MS7ueNp09a4KpEO2d0UYfbk3xxWze2TB02ns7Nfw4DnTuePnmBZUck2SnJRXN85vIkHjOezs0+WFUvz+giNF/OKKCuXWRV+9t6tmC7bcyy29/mItxba99M8umMTgR70QaLX5PRX2Pvb63duo1bW7Kq6sCq2n2B+Q/O6C/gJNno5Vb5qbOSXJfkhKp69LqZVbVjktePn75rFo0tZVV1aFXdc4H5Ryd5yfjpXOyDVfWqjE4EW5Xk8a216zayuv1tbEu2W2/7W83LtSQWuPzsFUkOzeiKWVcmeWxz+dmfqqpTk7wio3c9rk5yS5J9k/xqRle6OifJ01trd82qx1mqqmOTHDt++oAk/zWjv+ovHM+7rrX2sg3WPyujy4GemdHlQJ+a0deWzkryrHm4sMuWbLfx148OTHJ+RpeqTZJH5N+/x/2q1tq6sOpWVZ2Y5PQkdyd5exb+rHx1a+309WqOzZzvb1u63brb32Z9ibxt+UjyCxl9vet7Se5K8q2MTrDYfda9LbVHRl8B+duMziq9MaOLPvwwyT9k9B3RmnWPM94+p2Z0tvFij9UL1Bye0R9FP8roY6B/zuiIYPtZ/z5LcbsleV6Sv8voypI/zuhyqtdkdK30/zLr32UJbbOW5Hz727Dt1tv+NjdH7gAwL+biM3cAmCfCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDP/H04+Eumvr7T1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the predictions\n",
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images,labels = next(dataiter)\n",
    "img = images[55].view(1,784)\n",
    "\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)  # I used model.forward here\n",
    "    \n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "#helper.view_classify(img.view(1, 28, 28), ps)\n",
    "plt.imshow(images[55].reshape(28,28))\n",
    "print(torch.argmax(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
